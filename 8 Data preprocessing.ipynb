{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2608fb20",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "Data preprocessing refers to the steps taken to prepare and clean raw data before it can be used for analysis or machine learning algorithms. It involves transforming and organizing the data in a way that makes it suitable for further processing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b356a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afb2ca8",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Data cleaning is an essential step in data preprocessing, aimed at handling missing values, removing duplicates, and addressing errors or outliers in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70d2a3d",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a264fa",
   "metadata": {},
   "source": [
    "#### Removing rows or columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996ab9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'Feature1': [1, 2, np.nan, 4, 5, 6, 8, 11, 32, 10],\n",
    "    'Feature2': [6, 10, 15, 30, 25, 21, 30, 42, 31, 51],\n",
    "    'Feature3': [6, 7, 8, np.nan, 10, 6, 8, 11, np.nan, 15],\n",
    "    'Feature4': [11, 12, 13, 14, 15, 7, 8, 11, 10, 30]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3425a7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data :\n",
      "    Feature1  Feature2  Feature3  Feature4\n",
      "0       1.0         6       6.0        11\n",
      "1       2.0        10       7.0        12\n",
      "2       NaN        15       8.0        13\n",
      "3       4.0        30       NaN        14\n",
      "4       5.0        25      10.0        15\n",
      "5       6.0        21       6.0         7\n",
      "6       8.0        30       8.0         8\n",
      "7      11.0        42      11.0        11\n",
      "8      32.0        31       NaN        10\n",
      "9      10.0        51      15.0        30\n",
      "Remove rows with missing values :\n",
      "    Feature1  Feature2  Feature3  Feature4\n",
      "0       1.0         6       6.0        11\n",
      "1       2.0        10       7.0        12\n",
      "4       5.0        25      10.0        15\n",
      "5       6.0        21       6.0         7\n",
      "6       8.0        30       8.0         8\n",
      "7      11.0        42      11.0        11\n",
      "9      10.0        51      15.0        30\n",
      "Remove columns with missing values :\n",
      "    Feature2  Feature4\n",
      "0         6        11\n",
      "1        10        12\n",
      "2        15        13\n",
      "3        30        14\n",
      "4        25        15\n",
      "5        21         7\n",
      "6        30         8\n",
      "7        42        11\n",
      "8        31        10\n",
      "9        51        30\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Data :\\n\",data)\n",
    "\n",
    "# Remove rows with missing values\n",
    "row_removed_data = data.dropna(axis=0)\n",
    "print(\"Remove rows with missing values :\\n\",row_removed_data)\n",
    "\n",
    "# Remove columns with missing values\n",
    "col_removed_data = data.dropna(axis=1)\n",
    "print(\"Remove columns with missing values :\\n\",col_removed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8f7de1",
   "metadata": {},
   "source": [
    "#### Filling missing values with mean, median, or mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5425c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data :\n",
      "    Feature1  Feature2  Feature3  Feature4\n",
      "0       1.0         6       6.0        11\n",
      "1       2.0        10       7.0        12\n",
      "2       NaN        15       8.0        13\n",
      "3       4.0        30       NaN        14\n",
      "4       5.0        25      10.0        15\n",
      "5       6.0        21       6.0         7\n",
      "6       8.0        30       8.0         8\n",
      "7      11.0        42      11.0        11\n",
      "8      32.0        31       NaN        10\n",
      "9      10.0        51      15.0        30\n",
      "\n",
      "Filled numerical missing values with mean :\n",
      "     Feature1  Feature2  Feature3  Feature4\n",
      "0   1.000000         6     6.000        11\n",
      "1   2.000000        10     7.000        12\n",
      "2   8.777778        15     8.000        13\n",
      "3   4.000000        30     8.875        14\n",
      "4   5.000000        25    10.000        15\n",
      "5   6.000000        21     6.000         7\n",
      "6   8.000000        30     8.000         8\n",
      "7  11.000000        42    11.000        11\n",
      "8  32.000000        31     8.875        10\n",
      "9  10.000000        51    15.000        30\n",
      "\n",
      "Filled numerical missing values with median :\n",
      "    Feature1  Feature2  Feature3  Feature4\n",
      "0       1.0         6       6.0        11\n",
      "1       2.0        10       7.0        12\n",
      "2       6.0        15       8.0        13\n",
      "3       4.0        30       8.0        14\n",
      "4       5.0        25      10.0        15\n",
      "5       6.0        21       6.0         7\n",
      "6       8.0        30       8.0         8\n",
      "7      11.0        42      11.0        11\n",
      "8      32.0        31       8.0        10\n",
      "9      10.0        51      15.0        30\n",
      "\n",
      "Filled numerical missing values with mode :\n",
      "    Feature1  Feature2  Feature3  Feature4\n",
      "0       1.0         6       6.0        11\n",
      "1       2.0        10       7.0        12\n",
      "2       1.0        15       8.0        13\n",
      "3       4.0        30      11.0        14\n",
      "4       5.0        25      10.0        15\n",
      "5       6.0        21       6.0         7\n",
      "6       8.0        30       8.0         8\n",
      "7      11.0        42      11.0        11\n",
      "8      32.0        31      11.0        10\n",
      "9      10.0        51      15.0        30\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Data :\\n\",data)\n",
    "\n",
    "# Fill numerical missing values with mean\n",
    "filled_mean_data = data.fillna(data.mean())\n",
    "print(\"\\nFilled numerical missing values with mean :\\n\",filled_mean_data)\n",
    "\n",
    "# Fill numerical missing values with median\n",
    "filled_median_data = data.fillna(data.median())\n",
    "print(\"\\nFilled numerical missing values with median :\\n\",filled_median_data)\n",
    "\n",
    "# Fill categorical missing values with mode\n",
    "filled_mode_feature1 = data[\"Feature1\"].fillna(stats.mode(data[\"Feature1\"]))\n",
    "filled_mode_feature2 = data[\"Feature2\"].fillna(stats.mode(data[\"Feature2\"]))\n",
    "filled_mode_feature3 = data[\"Feature3\"].fillna(stats.mode(data[\"Feature4\"]))\n",
    "filled_mode_feature4 = data[\"Feature4\"].fillna(stats.mode(data[\"Feature4\"]))\n",
    "filled_mode_data = pd.concat([filled_mode_feature1,filled_mode_feature2,filled_mode_feature3,filled_mode_feature4],axis=1)\n",
    "print(\"\\nFilled numerical missing values with mode :\\n\",filled_mode_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657cefb9",
   "metadata": {},
   "source": [
    "#### Forward filling or backward filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0672d1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset :\n",
      "    Feature1  Feature2  Feature3  Feature4\n",
      "0       1.0         6       6.0        11\n",
      "1       2.0        10       7.0        12\n",
      "2       NaN        15       8.0        13\n",
      "3       4.0        30       NaN        14\n",
      "4       5.0        25      10.0        15\n",
      "5       6.0        21       6.0         7\n",
      "6       8.0        30       8.0         8\n",
      "7      11.0        42      11.0        11\n",
      "8      32.0        31       NaN        10\n",
      "9      10.0        51      15.0        30\n",
      "\n",
      "Forward Filled Dataset :\n",
      "    Feature1  Feature2  Feature3  Feature4\n",
      "0       1.0         6       6.0        11\n",
      "1       2.0        10       7.0        12\n",
      "2       2.0        15       8.0        13\n",
      "3       4.0        30       8.0        14\n",
      "4       5.0        25      10.0        15\n",
      "5       6.0        21       6.0         7\n",
      "6       8.0        30       8.0         8\n",
      "7      11.0        42      11.0        11\n",
      "8      32.0        31      11.0        10\n",
      "9      10.0        51      15.0        30\n",
      "\n",
      "Backward Filled Dataset :\n",
      "    Feature1  Feature2  Feature3  Feature4\n",
      "0       1.0         6       6.0        11\n",
      "1       2.0        10       7.0        12\n",
      "2       4.0        15       8.0        13\n",
      "3       4.0        30      10.0        14\n",
      "4       5.0        25      10.0        15\n",
      "5       6.0        21       6.0         7\n",
      "6       8.0        30       8.0         8\n",
      "7      11.0        42      11.0        11\n",
      "8      32.0        31      15.0        10\n",
      "9      10.0        51      15.0        30\n"
     ]
    }
   ],
   "source": [
    "# Forward filling missing values\n",
    "data_ffill = data.ffill()\n",
    "\n",
    "# Backward filling missing values\n",
    "data_bfill = data.bfill()\n",
    "\n",
    "# Print the original dataset\n",
    "print(\"Original Dataset :\\n\",data)\n",
    "\n",
    "\n",
    "# Print the dataset after forward filling missing values\n",
    "print(\"\\nForward Filled Dataset :\\n\",data_ffill)\n",
    "\n",
    "\n",
    "# Print the dataset after backward filling missing values\n",
    "print(\"\\nBackward Filled Dataset :\\n\",data_bfill)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c1cb2",
   "metadata": {},
   "source": [
    "#### Replacing missing values with specific values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3bfab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset :\n",
      "    Feature1  Feature2  Feature3  Feature4\n",
      "0       1.0         6       6.0        11\n",
      "1       2.0        10       7.0        12\n",
      "2       NaN        15       8.0        13\n",
      "3       4.0        30       NaN        14\n",
      "4       5.0        25      10.0        15\n",
      "5       6.0        21       6.0         7\n",
      "6       8.0        30       8.0         8\n",
      "7      11.0        42      11.0        11\n",
      "8      32.0        31       NaN        10\n",
      "9      10.0        51      15.0        30\n",
      "\n",
      "Replace missing numerical values with -999 :\n",
      "    Feature1  Feature2  Feature3  Feature4\n",
      "0       1.0         6       6.0        11\n",
      "1       2.0        10       7.0        12\n",
      "2    -999.0        15       8.0        13\n",
      "3       4.0        30    -999.0        14\n",
      "4       5.0        25      10.0        15\n",
      "5       6.0        21       6.0         7\n",
      "6       8.0        30       8.0         8\n",
      "7      11.0        42      11.0        11\n",
      "8      32.0        31    -999.0        10\n",
      "9      10.0        51      15.0        30\n",
      "\n",
      "Replace missing categorical values with 'Unknown' :\n",
      "   Feature1  Feature2 Feature3  Feature4\n",
      "0      1.0         6      6.0        11\n",
      "1      2.0        10      7.0        12\n",
      "2  Unknown        15      8.0        13\n",
      "3      4.0        30  Unknown        14\n",
      "4      5.0        25     10.0        15\n",
      "5      6.0        21      6.0         7\n",
      "6      8.0        30      8.0         8\n",
      "7     11.0        42     11.0        11\n",
      "8     32.0        31  Unknown        10\n",
      "9     10.0        51     15.0        30\n"
     ]
    }
   ],
   "source": [
    "# Print the original dataset\n",
    "print(\"Original Dataset :\\n\",data)\n",
    "\n",
    "# Replace missing numerical values with -999\n",
    "replacing_999 = data.fillna(-999)\n",
    "print(\"\\nReplace missing numerical values with -999 :\\n\",replacing_999)\n",
    "\n",
    "# Replace missing categorical values with 'Unknown'\n",
    "replacing_unknown = data.fillna('Unknown')\n",
    "print(\"\\nReplace missing categorical values with 'Unknown' :\\n\",replacing_unknown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be3785",
   "metadata": {},
   "source": [
    "#### Using interpolation for filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edf84336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset :\n",
      "    Feature1  Feature2  Feature3  Feature4\n",
      "0       1.0         6       6.0        11\n",
      "1       2.0        10       7.0        12\n",
      "2       NaN        15       8.0        13\n",
      "3       4.0        30       NaN        14\n",
      "4       5.0        25      10.0        15\n",
      "5       6.0        21       6.0         7\n",
      "6       8.0        30       8.0         8\n",
      "7      11.0        42      11.0        11\n",
      "8      32.0        31       NaN        10\n",
      "9      10.0        51      15.0        30\n",
      "\n",
      "Interpolate missing numerical values :\n",
      "    Feature1  Feature2  Feature3  Feature4\n",
      "0       1.0         6       6.0        11\n",
      "1       2.0        10       7.0        12\n",
      "2       3.0        15       8.0        13\n",
      "3       4.0        30       9.0        14\n",
      "4       5.0        25      10.0        15\n",
      "5       6.0        21       6.0         7\n",
      "6       8.0        30       8.0         8\n",
      "7      11.0        42      11.0        11\n",
      "8      32.0        31      13.0        10\n",
      "9      10.0        51      15.0        30\n"
     ]
    }
   ],
   "source": [
    "# Print the original dataset\n",
    "print(\"Original Dataset :\\n\",data)\n",
    "\n",
    "# Interpolate missing numerical values\n",
    "data_interpolated = data.interpolate()\n",
    "print(\"\\nInterpolate missing numerical values :\\n\",data_interpolated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a0770",
   "metadata": {},
   "source": [
    "#### Multiple imputation using fancyimpute library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ce47b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Jul 17 11:15:31 PM: Encountered unexpected exception importing solver CVXOPT:\n",
      "ImportError('DLL load failed while importing base: The specified module could not be found.')\n",
      "(CVXPY) Jul 17 11:15:31 PM: Encountered unexpected exception importing solver GLPK:\n",
      "ImportError('DLL load failed while importing base: The specified module could not be found.')\n",
      "(CVXPY) Jul 17 11:15:31 PM: Encountered unexpected exception importing solver GLPK_MI:\n",
      "ImportError('DLL load failed while importing base: The specified module could not be found.')\n",
      "Original Dataset:\n",
      "     A    B    C\n",
      "0  1.0  NaN  1.0\n",
      "1  NaN  2.0  2.0\n",
      "2  3.0  3.0  NaN\n",
      "3  NaN  NaN  NaN\n",
      "4  5.0  5.0  5.0\n",
      "\n",
      "Imputed Dataset:\n",
      "          A         B         C\n",
      "0  1.000000  1.000063  1.000000\n",
      "1  1.999852  2.000000  2.000000\n",
      "2  3.000000  3.000000  3.000014\n",
      "3  2.749963  2.750016  2.750004\n",
      "4  5.000000  5.000000  5.000000\n"
     ]
    }
   ],
   "source": [
    "from fancyimpute import IterativeImputer\n",
    "\n",
    "# Create sample dataset with missing values\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, np.nan, 3, np.nan, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': [1, 2, np.nan, np.nan, 5]\n",
    "})\n",
    "\n",
    "# Perform multiple imputation\n",
    "imputer = IterativeImputer()\n",
    "data_imputed = imputer.fit_transform(data)\n",
    "\n",
    "# Convert the imputed array back to a DataFrame\n",
    "data_imputed = pd.DataFrame(data_imputed, columns=data.columns)\n",
    "\n",
    "# Print the original dataset\n",
    "print(\"Original Dataset:\")\n",
    "print(data)\n",
    "\n",
    "# Print the imputed dataset\n",
    "print(\"\\nImputed Dataset:\")\n",
    "print(data_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8180819",
   "metadata": {},
   "source": [
    "#### Filling missing values using predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfad7d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset :\n",
      "      A    B    C\n",
      "0  1.0  NaN  1.0\n",
      "1  NaN  2.0  2.0\n",
      "2  3.0  3.0  NaN\n",
      "3  NaN  NaN  NaN\n",
      "4  5.0  5.0  5.0\n",
      "\n",
      "[SoftImpute] Max Singular Value of X_init = 9.703555\n",
      "[SoftImpute] Iter 1: observed MAE=0.092302 rank=3\n",
      "[SoftImpute] Iter 2: observed MAE=0.092414 rank=3\n",
      "[SoftImpute] Iter 3: observed MAE=0.092508 rank=3\n",
      "[SoftImpute] Iter 4: observed MAE=0.092584 rank=3\n",
      "[SoftImpute] Iter 5: observed MAE=0.092639 rank=3\n",
      "[SoftImpute] Iter 6: observed MAE=0.092673 rank=3\n",
      "[SoftImpute] Iter 7: observed MAE=0.092684 rank=3\n",
      "[SoftImpute] Iter 8: observed MAE=0.092669 rank=3\n",
      "[SoftImpute] Iter 9: observed MAE=0.092627 rank=3\n",
      "[SoftImpute] Iter 10: observed MAE=0.092554 rank=3\n",
      "[SoftImpute] Iter 11: observed MAE=0.092447 rank=3\n",
      "[SoftImpute] Iter 12: observed MAE=0.092301 rank=3\n",
      "[SoftImpute] Iter 13: observed MAE=0.092111 rank=3\n",
      "[SoftImpute] Iter 14: observed MAE=0.091870 rank=3\n",
      "[SoftImpute] Iter 15: observed MAE=0.091569 rank=3\n",
      "[SoftImpute] Iter 16: observed MAE=0.091195 rank=3\n",
      "[SoftImpute] Iter 17: observed MAE=0.090387 rank=2\n",
      "[SoftImpute] Iter 18: observed MAE=0.083420 rank=2\n",
      "[SoftImpute] Iter 19: observed MAE=0.079818 rank=2\n",
      "[SoftImpute] Iter 20: observed MAE=0.077962 rank=2\n",
      "[SoftImpute] Iter 21: observed MAE=0.076999 rank=2\n",
      "[SoftImpute] Iter 22: observed MAE=0.076488 rank=2\n",
      "[SoftImpute] Iter 23: observed MAE=0.076205 rank=2\n",
      "[SoftImpute] Iter 24: observed MAE=0.076038 rank=2\n",
      "[SoftImpute] Iter 25: observed MAE=0.075932 rank=2\n",
      "[SoftImpute] Iter 26: observed MAE=0.075862 rank=2\n",
      "[SoftImpute] Iter 27: observed MAE=0.075822 rank=2\n",
      "[SoftImpute] Iter 28: observed MAE=0.075458 rank=1\n",
      "[SoftImpute] Iter 29: observed MAE=0.069518 rank=1\n",
      "[SoftImpute] Iter 30: observed MAE=0.067249 rank=1\n",
      "[SoftImpute] Iter 31: observed MAE=0.066347 rank=1\n",
      "[SoftImpute] Iter 32: observed MAE=0.065973 rank=1\n",
      "[SoftImpute] Iter 33: observed MAE=0.065812 rank=1\n",
      "[SoftImpute] Stopped after iteration 33 for lambda=0.194071\n",
      "\n",
      "Imputed Dataset:\n",
      "          A         B        C\n",
      "0  1.000000  0.977734  1.00000\n",
      "1  1.949875  2.000000  2.00000\n",
      "2  3.000000  3.000000  2.90091\n",
      "3 -0.000000 -0.000000 -0.00000\n",
      "4  5.000000  5.000000  5.00000\n"
     ]
    }
   ],
   "source": [
    "from fancyimpute import SoftImpute\n",
    "\n",
    "# Create sample dataset with missing values\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, np.nan, 3, np.nan, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': [1, 2, np.nan, np.nan, 5]\n",
    "})\n",
    "\n",
    "# Print the original dataset\n",
    "print(\"Original Dataset :\\n\",data)\n",
    "print(\"\")\n",
    "\n",
    "# Perform matrix completion using SoftImpute\n",
    "imputer = SoftImpute()\n",
    "data_imputed = imputer.fit_transform(data)\n",
    "\n",
    "# Convert the imputed array back to a DataFrame\n",
    "data_imputed = pd.DataFrame(data_imputed, columns=data.columns)\n",
    "\n",
    "# Print the imputed dataset\n",
    "print(\"\\nImputed Dataset:\")\n",
    "print(data_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331dd889",
   "metadata": {},
   "source": [
    "#### Filling missing values using K-nearest neighbors (KNN) imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13b246a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset :\n",
      "      A    B    C\n",
      "0  1.0  NaN  1.0\n",
      "1  NaN  2.0  2.0\n",
      "2  3.0  3.0  NaN\n",
      "3  NaN  NaN  NaN\n",
      "4  5.0  5.0  5.0\n",
      "\n",
      "Imputing row 1/5 with 1 missing, elapsed time: 0.001\n",
      "[KNN] Warning: 3/15 still missing after imputation, replacing with 0\n",
      "Filling missing values using K-nearest neighbors (KNN) imputation :\n",
      " [[1.         2.33333333 1.        ]\n",
      " [2.15789468 2.         2.        ]\n",
      " [3.         3.         2.33333333]\n",
      " [0.         0.         0.        ]\n",
      " [5.         5.         5.        ]]\n"
     ]
    }
   ],
   "source": [
    "from fancyimpute import KNN\n",
    "\n",
    "# Print the original dataset\n",
    "print(\"Original Dataset :\\n\",data)\n",
    "print(\"\")\n",
    "\n",
    "# Create an instance of KNN imputer\n",
    "imputer = KNN()\n",
    "data_imputed = imputer.fit_transform(data)\n",
    "print(\"Filling missing values using K-nearest neighbors (KNN) imputation :\\n\",data_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f079de",
   "metadata": {},
   "source": [
    "#### Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d033dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset :\n",
      "      A    B    C\n",
      "0  1.0  NaN  1.0\n",
      "1  NaN  2.0  2.0\n",
      "2  3.0  3.0  NaN\n",
      "3  NaN  NaN  NaN\n",
      "4  5.0  5.0  5.0\n",
      "\n",
      "[SoftImpute] Max Singular Value of X_init = 9.703555\n",
      "[SoftImpute] Iter 1: observed MAE=0.092302 rank=3\n",
      "[SoftImpute] Iter 2: observed MAE=0.092414 rank=3\n",
      "[SoftImpute] Iter 3: observed MAE=0.092508 rank=3\n",
      "[SoftImpute] Iter 4: observed MAE=0.092584 rank=3\n",
      "[SoftImpute] Iter 5: observed MAE=0.092639 rank=3\n",
      "[SoftImpute] Iter 6: observed MAE=0.092673 rank=3\n",
      "[SoftImpute] Iter 7: observed MAE=0.092684 rank=3\n",
      "[SoftImpute] Iter 8: observed MAE=0.092669 rank=3\n",
      "[SoftImpute] Iter 9: observed MAE=0.092627 rank=3\n",
      "[SoftImpute] Iter 10: observed MAE=0.092554 rank=3\n",
      "[SoftImpute] Iter 11: observed MAE=0.092447 rank=3\n",
      "[SoftImpute] Iter 12: observed MAE=0.092301 rank=3\n",
      "[SoftImpute] Iter 13: observed MAE=0.092111 rank=3\n",
      "[SoftImpute] Iter 14: observed MAE=0.091870 rank=3\n",
      "[SoftImpute] Iter 15: observed MAE=0.091569 rank=3\n",
      "[SoftImpute] Iter 16: observed MAE=0.091195 rank=3\n",
      "[SoftImpute] Iter 17: observed MAE=0.090387 rank=2\n",
      "[SoftImpute] Iter 18: observed MAE=0.083420 rank=2\n",
      "[SoftImpute] Iter 19: observed MAE=0.079818 rank=2\n",
      "[SoftImpute] Iter 20: observed MAE=0.077962 rank=2\n",
      "[SoftImpute] Iter 21: observed MAE=0.076999 rank=2\n",
      "[SoftImpute] Iter 22: observed MAE=0.076488 rank=2\n",
      "[SoftImpute] Iter 23: observed MAE=0.076205 rank=2\n",
      "[SoftImpute] Iter 24: observed MAE=0.076038 rank=2\n",
      "[SoftImpute] Iter 25: observed MAE=0.075932 rank=2\n",
      "[SoftImpute] Iter 26: observed MAE=0.075862 rank=2\n",
      "[SoftImpute] Iter 27: observed MAE=0.075822 rank=2\n",
      "[SoftImpute] Iter 28: observed MAE=0.075458 rank=1\n",
      "[SoftImpute] Iter 29: observed MAE=0.069518 rank=1\n",
      "[SoftImpute] Iter 30: observed MAE=0.067249 rank=1\n",
      "[SoftImpute] Iter 31: observed MAE=0.066347 rank=1\n",
      "[SoftImpute] Iter 32: observed MAE=0.065973 rank=1\n",
      "[SoftImpute] Iter 33: observed MAE=0.065812 rank=1\n",
      "[SoftImpute] Stopped after iteration 33 for lambda=0.194071\n",
      "\n",
      "Matrix Factorization Data :\n",
      " [[ 1.          0.97773356  1.        ]\n",
      " [ 1.9498746   2.          2.        ]\n",
      " [ 3.          3.          2.90091019]\n",
      " [-0.         -0.         -0.        ]\n",
      " [ 5.          5.          5.        ]]\n"
     ]
    }
   ],
   "source": [
    "from fancyimpute import SoftImpute\n",
    "\n",
    "# Print the original dataset\n",
    "print(\"Original Dataset :\\n\",data)\n",
    "print(\"\")\n",
    "\n",
    "# Create an instance of SoftImpute imputer\n",
    "imputer = SoftImpute()\n",
    "data_imputed = imputer.fit_transform(data)\n",
    "print(\"\\nMatrix Factorization Data :\\n\",data_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65861aa",
   "metadata": {},
   "source": [
    "### Handling Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1878ed1",
   "metadata": {},
   "source": [
    "#### Identifying duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae3e4d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "   ID   Name  Age\n",
      "0   1   John   25\n",
      "1   2   Jane   30\n",
      "2   3   Mike   35\n",
      "3   4   Emma   40\n",
      "4   1   John   25\n",
      "5   2   Jane   30\n",
      "6   5  David   45\n",
      "\n",
      "Duplicates (All Columns):\n",
      "   ID  Name  Age\n",
      "4   1  John   25\n",
      "5   2  Jane   30\n",
      "\n",
      "Duplicates (Specific Columns):\n",
      "   ID  Name  Age\n",
      "4   1  John   25\n",
      "5   2  Jane   30\n"
     ]
    }
   ],
   "source": [
    "# Create sample dataset with duplicates\n",
    "data = pd.DataFrame({\n",
    "    'ID': [1, 2, 3, 4, 1, 2, 5],\n",
    "    'Name': ['John', 'Jane', 'Mike', 'Emma', 'John', 'Jane', 'David'],\n",
    "    'Age': [25, 30, 35, 40, 25, 30, 45]\n",
    "})\n",
    "\n",
    "# Identify duplicates based on all columns\n",
    "duplicates_all = data[data.duplicated()]\n",
    "\n",
    "# Identify duplicates based on specific columns\n",
    "columns_to_check = ['ID', 'Name']\n",
    "duplicates_specific = data[data.duplicated(subset=columns_to_check)]\n",
    "\n",
    "# Print the original dataset\n",
    "print(\"Original Dataset:\")\n",
    "print(data)\n",
    "print()\n",
    "\n",
    "# Print duplicates based on all columns\n",
    "print(\"Duplicates (All Columns):\")\n",
    "print(duplicates_all)\n",
    "print()\n",
    "\n",
    "# Print duplicates based on specific columns\n",
    "print(\"Duplicates (Specific Columns):\")\n",
    "print(duplicates_specific)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3452e351",
   "metadata": {},
   "source": [
    "#### Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce8d19d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "   ID   Name  Age\n",
      "0   1   John   25\n",
      "1   2   Jane   30\n",
      "2   3   Mike   35\n",
      "3   4   Emma   40\n",
      "4   1   John   25\n",
      "5   2   Jane   30\n",
      "6   5  David   45\n",
      "\n",
      "Dataset after Removing Duplicates:\n",
      "   ID   Name  Age\n",
      "0   1   John   25\n",
      "1   2   Jane   30\n",
      "2   3   Mike   35\n",
      "3   4   Emma   40\n",
      "6   5  David   45\n"
     ]
    }
   ],
   "source": [
    "# Print the original dataset\n",
    "print(\"Original Dataset:\")\n",
    "print(data)\n",
    "\n",
    "# Remove duplicates based on all columns\n",
    "data_duplicates_removed = data.drop_duplicates()\n",
    "\n",
    "# Print the dataset after removing duplicates\n",
    "print(\"\\nDataset after Removing Duplicates:\")\n",
    "print(data_duplicates_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c096c759",
   "metadata": {},
   "source": [
    "#### Keeping the first occurrence and removing subsequent duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9d190c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "   ID   Name  Age\n",
      "0   1   John   25\n",
      "1   2   Jane   30\n",
      "2   3   Mike   35\n",
      "3   4   Emma   40\n",
      "4   1   John   25\n",
      "5   2   Jane   30\n",
      "6   5  David   45\n",
      "\n",
      "Keep the first occurrence and remove subsequent duplicates :\n",
      "\n",
      "   ID   Name  Age\n",
      "0   1   John   25\n",
      "1   2   Jane   30\n",
      "2   3   Mike   35\n",
      "3   4   Emma   40\n",
      "6   5  David   45\n"
     ]
    }
   ],
   "source": [
    "# Print the original dataset\n",
    "print(\"Original Dataset:\")\n",
    "print(data)\n",
    "\n",
    "# Keep the first occurrence and remove subsequent duplicates\n",
    "data_duplicates_removed = data.drop_duplicates(keep='first')\n",
    "print(\"\\nKeep the first occurrence and remove subsequent duplicates :\\n\")\n",
    "print(data_duplicates_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e1f27",
   "metadata": {},
   "source": [
    "#### Keeping the last occurrence and removing previous duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "697d2cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "   ID   Name  Age\n",
      "0   1   John   25\n",
      "1   2   Jane   30\n",
      "2   3   Mike   35\n",
      "3   4   Emma   40\n",
      "4   1   John   25\n",
      "5   2   Jane   30\n",
      "6   5  David   45\n",
      "\n",
      "Keep the last occurrence and remove subsequent duplicates :\n",
      "\n",
      "   ID   Name  Age\n",
      "2   3   Mike   35\n",
      "3   4   Emma   40\n",
      "4   1   John   25\n",
      "5   2   Jane   30\n",
      "6   5  David   45\n"
     ]
    }
   ],
   "source": [
    "# Print the original dataset\n",
    "print(\"Original Dataset:\")\n",
    "print(data)\n",
    "\n",
    "# Keep the last occurrence and remove previous duplicates\n",
    "data_duplicates_removed = data.drop_duplicates(keep='last')\n",
    "print(\"\\nKeep the last occurrence and remove subsequent duplicates :\\n\")\n",
    "print(data_duplicates_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897433c5",
   "metadata": {},
   "source": [
    "### Handling Errors and Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca84fdc",
   "metadata": {},
   "source": [
    "#### Visual Inspection and Statistical Analysis\n",
    "Visualize the data using plots (e.g., scatter plots, histograms, box plots) to identify potential errors or outliers.\n",
    "Calculate summary statistics (e.g., mean, median, standard deviation) and identify values that deviate significantly from the expected range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513dc2c1",
   "metadata": {},
   "source": [
    "#### Winsorization\n",
    "Winsorization replaces extreme values with less extreme values to reduce the impact of outliers. It involves capping or flooring the extreme values to a specified percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "142c80b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "    A    B\n",
      "0   1   10\n",
      "1   2   20\n",
      "2   3   30\n",
      "3   4   40\n",
      "4   5   50\n",
      "5   6   60\n",
      "6   7   70\n",
      "7   8   80\n",
      "8   9   90\n",
      "9  10  100\n",
      "\n",
      "Dataset after Winsorization:\n",
      "   A    B\n",
      "0  2   10\n",
      "1  2   20\n",
      "2  3   30\n",
      "3  4   40\n",
      "4  5   50\n",
      "5  6   60\n",
      "6  7   70\n",
      "7  8   80\n",
      "8  9   90\n",
      "9  9  100\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# Create sample dataset with outliers\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'B': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "})\n",
    "\n",
    "# Print the original dataset\n",
    "print(\"Original Dataset:\")\n",
    "print(data)\n",
    "\n",
    "# Apply winsorization on column 'A'\n",
    "winsorized_A = winsorize(data['A'], limits=(0.1, 0.1))\n",
    "\n",
    "# Create a new DataFrame with winsorized values\n",
    "data_winsorized = data.copy()\n",
    "data_winsorized['A'] = winsorized_A\n",
    "\n",
    "# Print the dataset after winsorization\n",
    "print(\"\\nDataset after Winsorization:\")\n",
    "print(data_winsorized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039dc210",
   "metadata": {},
   "source": [
    "#### Trimming\n",
    "Trimming removes a specified percentage of extreme values from the dataset. It can be used when extreme values are unlikely to represent errors and should not be included in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a61cc644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "     A    B\n",
      "0    1   11\n",
      "1    2   12\n",
      "2    3   13\n",
      "3    4   14\n",
      "4    5   15\n",
      "5  100   16\n",
      "6    7   17\n",
      "7    8   18\n",
      "8    9  200\n",
      "9   10   20\n",
      "\n",
      "Dataset after Trimming:\n",
      "       A       B\n",
      "0   1.45   11.45\n",
      "1   2.00   12.00\n",
      "2   3.00   13.00\n",
      "3   4.00   14.00\n",
      "4   5.00   15.00\n",
      "5  59.50   16.00\n",
      "6   7.00   17.00\n",
      "7   8.00   18.00\n",
      "8   9.00  119.00\n",
      "9  10.00   20.00\n"
     ]
    }
   ],
   "source": [
    "# Create sample dataset with outliers\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'B': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "})\n",
    "\n",
    "# Add outliers to the dataset\n",
    "data.loc[5, 'A'] = 100\n",
    "data.loc[8, 'B'] = 200\n",
    "\n",
    "# Print the original dataset\n",
    "print(\"Original Dataset:\")\n",
    "print(data)\n",
    "\n",
    "# Trim outliers using clipping\n",
    "trimmed_data = data.clip(lower=data.quantile(0.05), upper=data.quantile(0.95), axis=1)\n",
    "\n",
    "# Print the dataset after trimming\n",
    "print(\"\\nDataset after Trimming:\")\n",
    "print(trimmed_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2a1e46",
   "metadata": {},
   "source": [
    "#### Statistical Methods\n",
    "Statistical techniques such as z-score or modified z-score can be used to identify and handle outliers based on their deviation from the mean or median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecc3a6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "     A     B    C\n",
      "0    1    10  100\n",
      "1    2    20  200\n",
      "2    3    30  300\n",
      "3    4    40  400\n",
      "4    5    50  500\n",
      "5  200  1000  100\n",
      "\n",
      "Identified Outliers:\n",
      "Empty DataFrame\n",
      "Columns: [A, B, C]\n",
      "Index: []\n",
      "\n",
      "Dataset after Removing Outliers:\n",
      "     A     B    C\n",
      "0    1    10  100\n",
      "1    2    20  200\n",
      "2    3    30  300\n",
      "3    4    40  400\n",
      "4    5    50  500\n",
      "5  200  1000  100\n"
     ]
    }
   ],
   "source": [
    "# Create sample dataset with outliers\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5, 200],\n",
    "    'B': [10, 20, 30, 40, 50, 1000],\n",
    "    'C': [100, 200, 300, 400, 500, 100],\n",
    "})\n",
    "\n",
    "# Print the original dataset\n",
    "print(\"Original Dataset:\")\n",
    "print(data)\n",
    "\n",
    "# Calculate the mean and standard deviation for each column\n",
    "means = data.mean()\n",
    "stds = data.std()\n",
    "\n",
    "# Define the threshold for outliers (e.g., beyond 3 standard deviations)\n",
    "threshold = 3\n",
    "\n",
    "# Identify outliers using the z-score method\n",
    "outliers = data[(np.abs((data - means) / stds) > threshold).any(axis=1)]\n",
    "\n",
    "# Print the identified outliers\n",
    "print(\"\\nIdentified Outliers:\")\n",
    "print(outliers)\n",
    "\n",
    "# Remove outliers using the z-score method\n",
    "data_no_outliers = data[(np.abs((data - means) / stds) <= threshold).all(axis=1)]\n",
    "\n",
    "# Print the dataset after removing outliers\n",
    "print(\"\\nDataset after Removing Outliers:\")\n",
    "print(data_no_outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370820d8",
   "metadata": {},
   "source": [
    "#### Robust Statistical Methods\n",
    "Robust statistical methods, like the median absolute deviation (MAD), are less sensitive to outliers compared to traditional methods that use mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44a8084a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "   A    B     C\n",
      "0  1   10   100\n",
      "1  2   20   200\n",
      "2  3   30   300\n",
      "3  4   40  4000\n",
      "4  5   50   500\n",
      "5  6   60   600\n",
      "6  7  700   700\n",
      "\n",
      "Dataset after Removing Outliers:\n",
      "   A   B    C\n",
      "0  1  10  100\n",
      "1  2  20  200\n",
      "2  3  30  300\n",
      "4  5  50  500\n",
      "5  6  60  600\n"
     ]
    }
   ],
   "source": [
    "# Create sample dataset with errors and outliers\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'B': [10, 20, 30, 40, 50, 60, 700],\n",
    "    'C': [100, 200, 300, 4000, 500, 600, 700]\n",
    "})\n",
    "\n",
    "# Print the original dataset\n",
    "print(\"Original Dataset:\")\n",
    "print(data)\n",
    "\n",
    "# Calculate the median absolute deviation (MAD)\n",
    "median = data.median()\n",
    "mad = (data - median).abs().median()\n",
    "\n",
    "# Define the threshold for outliers\n",
    "threshold = 3.5\n",
    "\n",
    "# Identify outliers based on the MAD\n",
    "outliers_mad = (np.abs((data - median) / mad) > threshold).any(axis=1)\n",
    "\n",
    "# Identify outliers based on the IQR\n",
    "q1 = data.quantile(0.25)\n",
    "q3 = data.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "outliers_iqr = ((data < lower_bound) | (data > upper_bound)).any(axis=1)\n",
    "\n",
    "# Remove outliers from the dataset\n",
    "data_cleaned = data[~(outliers_mad | outliers_iqr)]\n",
    "\n",
    "# Print the dataset after removing outliers\n",
    "print(\"\\nDataset after Removing Outliers:\")\n",
    "print(data_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af795ccf",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d564e5",
   "metadata": {},
   "source": [
    "#### Scaling/Normalization\n",
    "Scaling or normalization is used to bring numerical features onto a similar scale, preventing any single feature from dominating the analysis due to its larger magnitude. Common scaling techniques include min-max scaling and standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6c3a949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data :\n",
      " [[10  3  5]\n",
      " [20  6  9]\n",
      " [ 5  1  2]\n",
      " [15  4  7]\n",
      " [ 8  2  4]]\n",
      "\n",
      "Scaled Data :\n",
      " [[0.33333333 0.4        0.42857143]\n",
      " [1.         1.         1.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.66666667 0.6        0.71428571]\n",
      " [0.2        0.2        0.28571429]]\n",
      "\n",
      "Standard Data :\n",
      " [[-0.30108397 -0.11624764 -0.16552118]\n",
      " [ 1.58069085  1.62746694  1.4896906 ]\n",
      " [-1.24197138 -1.27872403 -1.40693001]\n",
      " [ 0.63980344  0.46499055  0.66208471]\n",
      " [-0.67743894 -0.69748583 -0.57932412]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Create a sample dataset\n",
    "data = np.array([[10, 3, 5],\n",
    "                [20, 6, 9],\n",
    "                [5, 1, 2],\n",
    "                [15, 4, 7],\n",
    "                [8, 2, 4]])\n",
    "\n",
    "print(\"Original Data :\\n\",data)\n",
    "print(\"\")\n",
    "# Min-max scaling\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "print(\"Scaled Data :\\n\",data_scaled)\n",
    "\n",
    "print(\"\")\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "data_standardized = scaler.fit_transform(data)\n",
    "print(\"Standard Data :\\n\",data_standardized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142b3203",
   "metadata": {},
   "source": [
    "#### Logarithmic Transformation\n",
    "Logarithmic transformation is used to reduce the impact of large values and handle positively skewed distributions. It compresses the scale of the data and can make it more symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21072963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data :\n",
      " [    10    100   1000  10000 100000]\n",
      "Log Transform Data :\n",
      " [ 2.39789527  4.61512052  6.90875478  9.21044037 11.51293546]\n"
     ]
    }
   ],
   "source": [
    "# Create a sample dataset\n",
    "data = np.array([10, 100, 1000, 10000, 100000])\n",
    "\n",
    "print(\"Original Data :\\n\",data)\n",
    "# Logarithmic transformation\n",
    "data_log_transformed = np.log1p(data)  # Log transformation with added 1 to handle zero or negative values\n",
    "print(\"Log Transform Data :\\n\",data_log_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8400cdc8",
   "metadata": {},
   "source": [
    "#### Power Transformation\n",
    "Power transformation, such as the Box-Cox transformation, is used to stabilize variance and normalize the data. It can be applied to handle data that violates assumptions of normality or homoscedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3619948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data :\n",
      " [1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "Power Transform Data :\n",
      " [0.         0.89887536 1.67448353 2.37952145 3.03633818 3.65711928\n",
      " 4.2494518  4.81847233 5.36786648]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import boxcox\n",
    "\n",
    "# Create a sample dataset\n",
    "data = np.array([1.0, 2.0, 3.0,4.0, 5.0, 6.0,7.0, 8.0, 9.0])\n",
    "\n",
    "print(\"Original Data :\\n\",data)\n",
    "\n",
    "# Box-Cox transformation\n",
    "data_transformed, lambda_val = boxcox(data)\n",
    "print(\"Power Transform Data :\\n\",data_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696a9ca",
   "metadata": {},
   "source": [
    "#### Binning/Discretization\n",
    "Binning or discretization is used to convert continuous numerical features into categorical features by grouping values into bins or intervals. This can help simplify the analysis and handle non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8754aa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data :\n",
      "    age  income\n",
      "0   25   50000\n",
      "1   37   75000\n",
      "2   42  100000\n",
      "3   18   25000\n",
      "4   51   80000\n",
      "5   29   60000\n",
      "6   36   90000\n",
      "7   22   40000\n",
      "8   45   95000\n",
      "9   33   70000\n",
      "Binning Data :\n",
      " [[1. 1.]\n",
      " [2. 3.]\n",
      " [3. 4.]\n",
      " [0. 0.]\n",
      " [4. 3.]\n",
      " [1. 2.]\n",
      " [2. 4.]\n",
      " [0. 1.]\n",
      " [4. 4.]\n",
      " [2. 3.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RACHIT\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:239: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'age': [25, 37, 42, 18, 51, 29, 36, 22, 45, 33],\n",
    "    'income': [50000, 75000, 100000, 25000, 80000, 60000, 90000, 40000, 95000, 70000]\n",
    "})\n",
    "\n",
    "print(\"Original Data :\\n\",data)\n",
    "\n",
    "# Binning into equal-width bins\n",
    "bin_discretizer = KBinsDiscretizer(n_bins=5, strategy='uniform', encode='ordinal')\n",
    "data_binned = bin_discretizer.fit_transform(data)\n",
    "\n",
    "print(\"Binning Data :\\n\",data_binned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277b78d9",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables\n",
    "Encoding categorical variables is necessary to represent them in a numerical format suitable for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7583ce",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding\n",
    "One-hot encoding is used to represent categorical variables as binary vectors. It creates new binary columns for each unique category in the variable, with a value of 1 indicating the presence of that category and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "169f1a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data :\n",
      "     Color    Size      Shape\n",
      "0     Red   Small     Circle\n",
      "1    Blue   Large  Rectangle\n",
      "2   Green  Medium   Triangle\n",
      "3     Red   Small     Circle\n",
      "4  Yellow  Medium     Square\n",
      "OneHot Encoder Data :\n",
      "   (0, 2)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 7)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 8)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (2, 5)\t1.0\n",
      "  (2, 10)\t1.0\n",
      "  (3, 2)\t1.0\n",
      "  (3, 6)\t1.0\n",
      "  (3, 7)\t1.0\n",
      "  (4, 3)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (4, 9)\t1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Color': ['Red', 'Blue', 'Green', 'Red', 'Yellow'],\n",
    "    'Size': ['Small', 'Large', 'Medium', 'Small', 'Medium'],\n",
    "    'Shape': ['Circle', 'Rectangle', 'Triangle', 'Circle', 'Square']\n",
    "})\n",
    "\n",
    "print(\"Original Data :\\n\",data)\n",
    "\n",
    "# One-hot encoding\n",
    "encoder = OneHotEncoder()\n",
    "data_encoded = encoder.fit_transform(data)\n",
    "\n",
    "print(\"OneHot Encoder Data :\\n\",data_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ac6ede",
   "metadata": {},
   "source": [
    "#### Label Encoding\n",
    "Label encoding assigns a numerical label to each unique category in a categorical variable. It is suitable for ordinal variables where the order of the categories matters. Each category is assigned a unique integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3776b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data :\n",
      "   Category    Size Label\n",
      "0      Red   Small     A\n",
      "1     Blue   Large     B\n",
      "2    Green  Medium     A\n",
      "3    Green   Large     C\n",
      "4      Red   Small     B\n",
      "5     Blue  Medium     C\n",
      "Label Encoder data :\n",
      "   Category    Size Label  Encoded label\n",
      "0      Red   Small     A              0\n",
      "1     Blue   Large     B              1\n",
      "2    Green  Medium     A              0\n",
      "3    Green   Large     C              2\n",
      "4      Red   Small     B              1\n",
      "5     Blue  Medium     C              2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Category': ['Red', 'Blue', 'Green', 'Green', 'Red', 'Blue'],\n",
    "    'Size': ['Small', 'Large', 'Medium', 'Large', 'Small', 'Medium'],\n",
    "    'Label': ['A', 'B', 'A', 'C', 'B', 'C']\n",
    "})\n",
    "\n",
    "print(\"Original Data :\\n\",data)\n",
    "\n",
    "\n",
    "# LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "data[\"Encoded label\"] = encoder.fit_transform(data['Label'])\n",
    "\n",
    "print(\"Label Encoder data :\\n\",data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39ffd8",
   "metadata": {},
   "source": [
    "#### Ordinal Encoding\n",
    "Ordinal encoding is similar to label encoding but is used when the categories have an inherent order or rank. It assigns integer labels to categories based on their order, preserving the ordinal relationship between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73131cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data :\n",
      " [['Red', 'Small'], ['Blue', 'Large'], ['Green', 'Medium'], ['Green', 'Large'], ['Red', 'Small'], ['Blue', 'Medium']]\n",
      "Encoded Data :\n",
      " [[2. 2.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [1. 0.]\n",
      " [2. 2.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Create a sample dataset\n",
    "data = [['Red', 'Small'], ['Blue', 'Large'], ['Green', 'Medium'], \n",
    "        ['Green', 'Large'], ['Red', 'Small'], ['Blue', 'Medium']]\n",
    "\n",
    "print(\"Original Data :\\n\",data)\n",
    "\n",
    "# Initialize OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_data = ordinal_encoder.fit_transform(data)\n",
    "\n",
    "# Print the encoded data\n",
    "print(\"Encoded Data :\\n\",encoded_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b396c88d",
   "metadata": {},
   "source": [
    "#### Binary Encoding\n",
    "Binary encoding represents each unique category with a binary code. It involves converting the categories to binary representation and then creating binary columns for each digit in the binary code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53c65eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data :\n",
      "   Category    Size Label\n",
      "0      Red   Small     A\n",
      "1     Blue   Large     B\n",
      "2    Green  Medium     A\n",
      "3    Green   Large     C\n",
      "4      Red   Small     B\n",
      "5     Blue  Medium     C\n",
      "Encoded Data :\n",
      "    Category_0  Category_1  Size_0  Size_1 Label\n",
      "0           0           1       0       1     A\n",
      "1           1           0       1       0     B\n",
      "2           1           1       1       1     A\n",
      "3           1           1       1       0     C\n",
      "4           0           1       0       1     B\n",
      "5           1           0       1       1     C\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Category': ['Red', 'Blue', 'Green', 'Green', 'Red', 'Blue'],\n",
    "    'Size': ['Small', 'Large', 'Medium', 'Large', 'Small', 'Medium'],\n",
    "    'Label': ['A', 'B', 'A', 'C', 'B', 'C']\n",
    "})\n",
    "\n",
    "print(\"Original Data :\\n\",data)\n",
    "\n",
    "# Specify the columns to be binary encoded\n",
    "columns_to_encode = ['Category', 'Size']\n",
    "\n",
    "# Initialize BinaryEncoder\n",
    "binary_encoder = ce.BinaryEncoder(cols=columns_to_encode)\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_data = binary_encoder.fit_transform(data)\n",
    "\n",
    "# Print the encoded data\n",
    "print(\"Encoded Data :\\n\",encoded_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ffd8bf",
   "metadata": {},
   "source": [
    "#### Frequency Encoding\n",
    "Frequency encoding replaces categories with their frequency of occurrence in the dataset. It assigns a numerical value representing the proportion of observations that belong to each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c55bad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data :\n",
      "   Category    Size Label\n",
      "0      Red   Small     A\n",
      "1     Blue   Large     B\n",
      "2    Green  Medium     A\n",
      "3    Green   Large     C\n",
      "4      Red   Small     B\n",
      "5     Blue  Medium     C\n",
      "Frequency Encoded Data :\n",
      "   Category    Size Label  Category_Frequency_Encoded  Size_Frequency_Encoded\n",
      "0      Red   Small     A                    0.333333                0.333333\n",
      "1     Blue   Large     B                    0.333333                0.333333\n",
      "2    Green  Medium     A                    0.333333                0.333333\n",
      "3    Green   Large     C                    0.333333                0.333333\n",
      "4      Red   Small     B                    0.333333                0.333333\n",
      "5     Blue  Medium     C                    0.333333                0.333333\n"
     ]
    }
   ],
   "source": [
    "# Create a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Category': ['Red', 'Blue', 'Green', 'Green', 'Red', 'Blue'],\n",
    "    'Size': ['Small', 'Large', 'Medium', 'Large', 'Small', 'Medium'],\n",
    "    'Label': ['A', 'B', 'A', 'C', 'B', 'C']\n",
    "})\n",
    "\n",
    "print(\"Original Data :\\n\",data)\n",
    "\n",
    "# Calculate the frequency of each category\n",
    "category_freq = data['Category'].value_counts(normalize=True)\n",
    "size_freq = data['Size'].value_counts(normalize=True)\n",
    "label_freq = data['Label'].value_counts(normalize=True)\n",
    "\n",
    "# Create frequency encoding mapping dictionaries\n",
    "category_mapping = category_freq.to_dict()\n",
    "size_mapping = size_freq.to_dict()\n",
    "label_mapping = label_freq.to_dict()\n",
    "\n",
    "# Perform frequency encoding\n",
    "data['Category_Frequency_Encoded'] = data['Category'].map(category_mapping)\n",
    "data['Size_Frequency_Encoded'] = data['Size'].map(size_mapping)\n",
    "\n",
    "print(\"Frequency Encoded Data :\\n\",data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932d9983",
   "metadata": {},
   "source": [
    "## Feature Selection/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af7d064",
   "metadata": {},
   "source": [
    "#### Univariate Feature Selection\n",
    "This method evaluates each feature independently based on statistical measures like chi-square, ANOVA F-value, or mutual information with the target variable. It selects the top-k features with the highest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90174bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset :\n",
      "    Feature1  Feature2  Feature3 Feature4  Target\n",
      "0  0.548814         2 -0.651715        A       0\n",
      "1  0.715189         3  0.000038        A       0\n",
      "2  0.602763         2  0.889754        C       0\n",
      "3  0.544883         0 -1.156281        B       1\n",
      "4  0.423655         8  0.397217        C       1\n",
      "Encoded Dataset :\n",
      "    Feature1  Feature2  Feature3  Target    A    B    C\n",
      "0  0.548814         2 -0.651715       0  1.0  0.0  0.0\n",
      "1  0.715189         3  0.000038       0  1.0  0.0  0.0\n",
      "2  0.602763         2  0.889754       0  0.0  0.0  1.0\n",
      "3  0.544883         0 -1.156281       1  0.0  1.0  0.0\n",
      "4  0.423655         8  0.397217       1  0.0  0.0  1.0\n",
      "Selected Features:\n",
      "Feature1\n",
      "Feature2\n",
      "A\n",
      "B\n",
      "C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RACHIT\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Feature4': np.random.choice(['A', 'B', 'C'], 100),\n",
    "    'Target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Print the original dataset\n",
    "print(\"Original Dataset :\\n\",data.head())\n",
    "\n",
    "# Perform one-hot encoding for the categorical feature\n",
    "onehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "encoded_feature4 = onehot_encoder.fit_transform(data[['Feature4']])\n",
    "\n",
    "# Create a new DataFrame with the encoded feature\n",
    "encoded_data = pd.concat([data.drop('Feature4', axis=1), pd.DataFrame(encoded_feature4, columns=onehot_encoder.categories_[0])], axis=1)\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "X = encoded_data.drop('Target', axis=1)\n",
    "y = encoded_data['Target']\n",
    "\n",
    "# Print the encoded dataset\n",
    "print(\"Encoded Dataset :\\n\",encoded_data.head())\n",
    "\n",
    "# Assuming you have X as your feature matrix and y as the target variable\n",
    "\n",
    "# Create an instance of SelectKBest with the desired scoring function\n",
    "selector = SelectKBest(score_func=f_classif, k=5)  # Select top 5 features\n",
    "\n",
    "# Apply feature selection\n",
    "selected_features = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Print the selected feature indices and their corresponding names\n",
    "selected_feature_names = [X.columns[i] for i in selected_indices]\n",
    "print(\"Selected Features:\")\n",
    "for feature_name in selected_feature_names:\n",
    "    print(feature_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a7ce77",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination (RFE)\n",
    "RFE recursively eliminates features by fitting a model and discarding the least important feature at each iteration until the desired number of features is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9bd865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "Feature1\n",
      "B\n",
      "C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RACHIT\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Feature4': np.random.choice(['A', 'B', 'C'], 100),\n",
    "    'Target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Perform one-hot encoding for the categorical feature\n",
    "onehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "encoded_feature4 = onehot_encoder.fit_transform(data[['Feature4']])\n",
    "\n",
    "# Create a new DataFrame with the encoded feature\n",
    "encoded_data = pd.concat([data.drop('Feature4', axis=1), pd.DataFrame(encoded_feature4, columns=onehot_encoder.categories_[0])], axis=1)\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "X = encoded_data.drop('Target', axis=1)\n",
    "y = encoded_data['Target']\n",
    "\n",
    "# Initialize the estimator (model) for feature importance estimation\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "# Initialize the Recursive Feature Elimination (RFE) object\n",
    "rfe = RFE(estimator, n_features_to_select=3)  # Select the top 2 features\n",
    "\n",
    "# Perform RFE feature selection\n",
    "selected_features = rfe.fit_transform(X, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = rfe.get_support(indices=True)\n",
    "\n",
    "# Print the selected feature indices and their corresponding names\n",
    "selected_feature_names = [X.columns[i] for i in selected_indices]\n",
    "print(\"Selected Features:\")\n",
    "for feature_name in selected_feature_names:\n",
    "    print(feature_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49154b",
   "metadata": {},
   "source": [
    "#### L1 Regularization (Lasso)\n",
    "L1 regularization can be used to induce sparsity in the coefficients of a linear model, thereby automatically selecting a subset of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66479a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "Feature2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Feature4': np.random.choice(['A', 'B', 'C'], 100),\n",
    "    'Target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Encode categorical feature\n",
    "data_encoded = pd.get_dummies(data, columns=['Feature4'], drop_first=True)\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "X = data_encoded.drop('Target', axis=1)\n",
    "y = data_encoded['Target']\n",
    "\n",
    "# Initialize the Lasso estimator\n",
    "lasso = Lasso(alpha=0.1)  # Set the regularization strength (alpha)\n",
    "\n",
    "# Fit the Lasso model to the data\n",
    "lasso.fit(X, y)\n",
    "\n",
    "# Get the feature importance scores\n",
    "feature_importances = lasso.coef_\n",
    "\n",
    "# Get the selected feature indices (non-zero coefficients)\n",
    "selected_indices = np.nonzero(feature_importances)[0]\n",
    "\n",
    "# Print the selected feature indices and their corresponding names\n",
    "selected_feature_names = X.columns[selected_indices]\n",
    "print(\"Selected Features:\")\n",
    "for feature_name in selected_feature_names:\n",
    "    print(feature_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5f2305",
   "metadata": {},
   "source": [
    "#### Recursive Feature Addition (RFA):\n",
    "RFA is the opposite of RFE. It starts with an empty set of features and iteratively adds one feature at a time based on a selected evaluation metric until a stopping criterion is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e7d3b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RACHIT\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Feature4': np.random.choice(['A', 'B', 'C'], 100),\n",
    "    'Target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Perform one-hot encoding for the categorical feature\n",
    "onehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "encoded_feature4 = onehot_encoder.fit_transform(data[['Feature4']])\n",
    "\n",
    "# Create a new DataFrame with the encoded feature\n",
    "encoded_data = pd.concat([data.drop('Feature4', axis=1), pd.DataFrame(encoded_feature4, columns=onehot_encoder.categories_[0])], axis=1)\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "X = encoded_data.drop('Target', axis=1)\n",
    "y = encoded_data['Target']\n",
    "\n",
    "# Initialize the estimator (model) for feature importance estimation\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "# Initialize the Recursive Feature Addition (RFA) object\n",
    "rfa = RFECV(estimator, cv=5)  # Use 5-fold cross-validation\n",
    "\n",
    "# Perform RFA feature selection\n",
    "selected_features = rfa.fit_transform(X, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = rfa.get_support(indices=True)\n",
    "\n",
    "# Print the selected feature indices and their corresponding names\n",
    "selected_feature_names = [X.columns[i] for i in selected_indices]\n",
    "print(\"Selected Features:\")\n",
    "for feature_name in selected_feature_names:\n",
    "    print(feature_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af9761",
   "metadata": {},
   "source": [
    "#### SelectFromModel:\n",
    "SelectFromModel is a meta-transformer that selects features based on the importance scores provided by a base model. It allows you to specify a threshold to control the number of selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ff5c8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "Feature1\n",
      "Feature3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "X = data.drop('Target', axis=1)\n",
    "y = data['Target']\n",
    "\n",
    "# Initialize the estimator (model) for feature importance estimation\n",
    "estimator = RandomForestClassifier()\n",
    "\n",
    "# Initialize the SelectFromModel object\n",
    "selector = SelectFromModel(estimator)\n",
    "\n",
    "# Perform feature selection\n",
    "selected_features = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Print the selected feature indices and their corresponding names\n",
    "selected_feature_names = [X.columns[i] for i in selected_indices]\n",
    "print(\"Selected Features:\")\n",
    "for feature_name in selected_feature_names:\n",
    "    print(feature_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779980bd",
   "metadata": {},
   "source": [
    "#### Correlation Matrix\n",
    "The correlation matrix can be used to identify highly correlated features and select only one representative feature from each correlated group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fa3618e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Correlated Features:\n",
      "Empty DataFrame\n",
      "Columns: [Feature, Highly Correlated Features]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Feature4': np.random.choice(['A', 'B', 'C'], 100),\n",
    "    'Target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = data.corr()\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Set the threshold for correlation value\n",
    "threshold = 0.3\n",
    "\n",
    "# Get the absolute correlation values above the threshold\n",
    "high_corr_features = corr_matrix[abs(corr_matrix) > threshold].stack().reset_index()\n",
    "\n",
    "# Filter out the self-correlations (diagonal elements) and duplicate correlations\n",
    "high_corr_features = high_corr_features[high_corr_features['level_0'] != high_corr_features['level_1']]\n",
    "\n",
    "# Get the unique pairs of highly correlated features\n",
    "unique_high_corr_features = high_corr_features.groupby('level_0')['level_1'].apply(set).reset_index()\n",
    "unique_high_corr_features.columns = ['Feature', 'Highly Correlated Features']\n",
    "\n",
    "# Print the highly correlated feature pairs\n",
    "print(\"Highly Correlated Features:\")\n",
    "print(unique_high_corr_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c85b6bf",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis (PCA) \n",
    "PCA is a popular technique that transforms the original features into a new set of uncorrelated variables called principal components. It aims to capture the maximum variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bd86597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio:\n",
      "[0.42444987 0.32299404]\n",
      "Principal Components:\n",
      "        PC1       PC2\n",
      "0 -0.941287  0.641507\n",
      "1 -0.078539  0.726065\n",
      "2  0.014491 -0.083057\n",
      "3 -1.706534  0.946253\n",
      "4  0.879801 -0.394987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "X = data.drop('Target', axis=1)\n",
    "y = data['Target']\n",
    "\n",
    "# Perform feature scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize PCA object\n",
    "pca = PCA(n_components=2)  # Set the number of principal components to keep\n",
    "\n",
    "# Perform PCA on the scaled features\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create a new DataFrame with the principal components\n",
    "principal_components = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(\"Explained Variance Ratio:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "# Print the principal components dataframe\n",
    "print(\"Principal Components:\")\n",
    "print(principal_components.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71429800",
   "metadata": {},
   "source": [
    "#### Random Forest Importance\n",
    "Random Forest Importance assigns an importance score to each feature based on how much the feature contributes to the accuracy of a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c938df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "      Feature  Importance\n",
      "0    Feature1    0.347744\n",
      "2    Feature3    0.312635\n",
      "1    Feature2    0.235444\n",
      "5  Feature4_C    0.042192\n",
      "4  Feature4_B    0.038426\n",
      "3  Feature4_A    0.023559\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Feature4': np.random.choice(['A', 'B', 'C'], 100),\n",
    "    'Target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Perform one-hot encoding for the categorical feature\n",
    "encoded_data = pd.get_dummies(data, columns=['Feature4'])\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "X = encoded_data.drop('Target', axis=1)\n",
    "y = encoded_data['Target']\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "rf_classifier.fit(X, y)\n",
    "\n",
    "# Get feature importances from the classifier\n",
    "importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Create a DataFrame of feature importances\n",
    "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "print(\"Feature Importances:\")\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c069eec",
   "metadata": {},
   "source": [
    "#### Independent Component Analysis (ICA)\n",
    "ICA is used to separate a multivariate signal into additive subcomponents by assuming the independence of the components. It can be used for feature extraction in scenarios where the underlying sources are statistically independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "548aa385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICA Features:\n",
      "       ICA1      ICA2\n",
      "0 -0.505701  1.004970\n",
      "1  0.049168  0.628112\n",
      "2  1.198251  0.925680\n",
      "3 -0.748373  1.720097\n",
      "4  0.178875 -1.093848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Feature4': np.random.choice(['A', 'B', 'C'], 100),\n",
    "    'Target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "X = data.drop('Target', axis=1)\n",
    "y = data['Target']\n",
    "\n",
    "# Perform one-hot encoding for the categorical feature\n",
    "X_encoded = pd.get_dummies(X, columns=['Feature4'])\n",
    "\n",
    "# Initialize the Independent Component Analysis (ICA) object\n",
    "ica = FastICA(n_components=2)  # Select the top 2 independent components\n",
    "\n",
    "# Perform ICA for feature extraction\n",
    "X_ica = ica.fit_transform(X_encoded)\n",
    "\n",
    "# Create a DataFrame with the extracted features\n",
    "ica_data = pd.DataFrame(X_ica, columns=['ICA1', 'ICA2'])\n",
    "\n",
    "# Print the extracted features\n",
    "print(\"ICA Features:\")\n",
    "print(ica_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b3730",
   "metadata": {},
   "source": [
    "#### Non-Negative Matrix Factorization (NMF)\n",
    "NMF is a technique that factorizes the data matrix into non-negative matrices, which can be interpreted as parts-based representation of the original data. It can be used for feature extraction when the features are non-negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a557f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "['Feature4_B' 'Target' 'Feature1' 'Feature3' 'Feature4_A' 'Feature2']\n",
      "['Feature4_A' 'Target' 'Feature2' 'Feature1' 'Feature3' 'Feature4_B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RACHIT\\AppData\\Local\\Temp\\ipykernel_6720\\2732190983.py:34: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  selected_feature_names = encoded_data.columns[selected_indices]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.randn(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Feature4': np.random.choice(['A', 'B', 'C'], 100),\n",
    "    'Target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Perform one-hot encoding for the categorical feature\n",
    "encoded_data = pd.get_dummies(data, columns=['Feature4'])\n",
    "\n",
    "# Apply log transformation and shift to make the values non-negative\n",
    "scaler = MinMaxScaler()\n",
    "X = np.log1p(scaler.fit_transform(encoded_data.drop('Target', axis=1)) + 1e-8)\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "y = encoded_data['Target']\n",
    "\n",
    "# Initialize the NMF object\n",
    "nmf = NMF(n_components=2)  # Select the top 2 components\n",
    "\n",
    "# Perform NMF feature selection\n",
    "selected_features = nmf.fit_transform(X)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = np.argsort(nmf.components_)[-2:]\n",
    "\n",
    "# Print the selected feature indices and their corresponding names\n",
    "selected_feature_names = encoded_data.columns[selected_indices]\n",
    "print(\"Selected Features:\")\n",
    "for feature_name in selected_feature_names:\n",
    "    print(feature_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067225c4",
   "metadata": {},
   "source": [
    "#### t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "t-SNE is a technique commonly used for data visualization and exploratory analysis. It maps high-dimensional data to a lower-dimensional space while preserving local relationships and capturing non-linear structures. t-SNE is particularly useful for visualizing clusters or identifying patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59383de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Feature4': np.random.choice(['A', 'B', 'C'], 100),\n",
    "    'Target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Perform one-hot encoding for the categorical feature\n",
    "encoded_data = pd.get_dummies(data, columns=['Feature4'])\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "X = encoded_data.drop('Target', axis=1)\n",
    "y = encoded_data['Target']\n",
    "\n",
    "# Initialize the t-SNE object\n",
    "tsne = TSNE(n_components=2)\n",
    "\n",
    "# Perform t-SNE transformation\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "# Visualize the t-SNE plot\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y)\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.title('t-SNE Visualization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20830a",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis (LDA)\n",
    "LDA is a supervised dimensionality reduction technique that aims to find a linear combination of features that maximizes class separability. It considers class labels in addition to the data itself, making it useful for classification tasks. LDA seeks to find discriminative features that maximize between-class variance while minimizing within-class variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a6a606d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features Shape: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Feature4': np.random.choice(['A', 'B', 'C'], 100),\n",
    "    'Target': np.random.randint(0, 3, 100)  # Increase the number of classes to 3\n",
    "})\n",
    "\n",
    "# Perform one-hot encoding for the categorical feature\n",
    "encoded_data = pd.get_dummies(data, columns=['Feature4'])\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "X = encoded_data.drop('Target', axis=1)\n",
    "y = encoded_data['Target']\n",
    "\n",
    "# Initialize the LDA object\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)  # Set the n_components value to 2 or less\n",
    "\n",
    "# Perform LDA feature selection\n",
    "selected_features = lda.fit_transform(X, y)\n",
    "\n",
    "# Print the selected feature shape\n",
    "print(\"Selected Features Shape:\", selected_features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ba4b9",
   "metadata": {},
   "source": [
    "#### Manifold Learning (e.g., Isomap, Locally Linear Embedding)\n",
    "Manifold Learning methods aim to capture the underlying non-linear structure of the data by mapping it to a lower-dimensional space. Techniques like Isomap and Locally Linear Embedding (LLE) preserve the local relationships of the data points and can reveal intricate structures in the data that may not be captured by linear methods like PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "205584f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isomap Transformed Features Shape: (100, 2)\n",
      "LLE Transformed Features Shape: (100, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import Isomap, LocallyLinearEmbedding\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(0)\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.randint(0, 10, 100),\n",
    "    'Feature3': np.random.normal(0, 1, 100),\n",
    "    'Target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Split the dataset into X (features) and y (target variable)\n",
    "X = data.drop('Target', axis=1)\n",
    "y = data['Target']\n",
    "\n",
    "# Initialize the Isomap object\n",
    "isomap = Isomap(n_components=2)  # Set the number of components to 2\n",
    "\n",
    "# Perform Isomap dimensionality reduction\n",
    "isomap_features = isomap.fit_transform(X)\n",
    "\n",
    "# Initialize the LLE object\n",
    "lle = LocallyLinearEmbedding(n_components=2)  # Set the number of components to 2\n",
    "\n",
    "# Perform LLE dimensionality reduction\n",
    "lle_features = lle.fit_transform(X)\n",
    "\n",
    "# Print the shape of the transformed features\n",
    "print(\"Isomap Transformed Features Shape:\", isomap_features.shape)\n",
    "print(\"LLE Transformed Features Shape:\", lle_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0524774",
   "metadata": {},
   "source": [
    "## Handling Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab64532e",
   "metadata": {},
   "source": [
    "#### Resampling Techniques\n",
    "Oversampling: Oversampling increases the number of instances in the minority class by replicating existing instances or generating synthetic samples. Common oversampling methods include Random Oversampling, SMOTE (Synthetic Minority Over-sampling Technique), and ADASYN (Adaptive Synthetic Sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a390e172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "0    898\n",
      "1    102\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Class Distribution after Random Oversampling:\n",
      "0    898\n",
      "1    898\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Class Distribution after Random Undersampling:\n",
      "1    102\n",
      "0    102\n",
      "Name: Target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Create a sample imbalanced dataset\n",
    "np.random.seed(0)\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=5,\n",
    "    n_informative=3,\n",
    "    n_redundant=2,\n",
    "    n_classes=2,\n",
    "    weights=[0.9, 0.1],  # Imbalanced class distribution\n",
    ")\n",
    "\n",
    "# Convert the dataset into a DataFrame\n",
    "data = pd.DataFrame(X, columns=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5'])\n",
    "data['Target'] = y\n",
    "\n",
    "# Check the class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(data['Target'].value_counts())\n",
    "\n",
    "# Perform random oversampling\n",
    "oversampled_data = resample(data[data['Target'] == 1], n_samples=data['Target'].value_counts()[0], replace=True)\n",
    "oversampled_data = pd.concat([data[data['Target'] == 0], oversampled_data])\n",
    "\n",
    "# Perform random undersampling\n",
    "undersampled_data = resample(data[data['Target'] == 0], n_samples=data['Target'].value_counts()[1], replace=False)\n",
    "undersampled_data = pd.concat([data[data['Target'] == 1], undersampled_data])\n",
    "\n",
    "# Check the class distribution after resampling\n",
    "print(\"\\nClass Distribution after Random Oversampling:\")\n",
    "print(oversampled_data['Target'].value_counts())\n",
    "\n",
    "print(\"\\nClass Distribution after Random Undersampling:\")\n",
    "print(undersampled_data['Target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4f53962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "0    898\n",
      "1    102\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Class Distribution after Random Oversampling:\n",
      "1    898\n",
      "0    898\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Class Distribution after SMOTE:\n",
      "1    898\n",
      "0    898\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Class Distribution after ADASYN:\n",
      "1    900\n",
      "0    898\n",
      "Name: Target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "\n",
    "# Create a sample imbalanced dataset\n",
    "np.random.seed(0)\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=5,\n",
    "    n_informative=3,\n",
    "    n_redundant=2,\n",
    "    n_classes=2,\n",
    "    weights=[0.9, 0.1],  # Imbalanced class distribution\n",
    ")\n",
    "\n",
    "# Convert the dataset into a DataFrame\n",
    "data = pd.DataFrame(X, columns=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5'])\n",
    "data['Target'] = y\n",
    "\n",
    "# Check the class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(data['Target'].value_counts())\n",
    "\n",
    "# Random Oversampling\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_ros, y_ros = ros.fit_resample(data.drop('Target', axis=1), data['Target'])\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=0)\n",
    "X_smote, y_smote = smote.fit_resample(data.drop('Target', axis=1), data['Target'])\n",
    "\n",
    "# ADASYN\n",
    "adasyn = ADASYN(random_state=0)\n",
    "X_adasyn, y_adasyn = adasyn.fit_resample(data.drop('Target', axis=1), data['Target'])\n",
    "\n",
    "# Check the class distribution after resampling\n",
    "print(\"\\nClass Distribution after Random Oversampling:\")\n",
    "print(pd.Series(y_ros).value_counts())\n",
    "\n",
    "print(\"\\nClass Distribution after SMOTE:\")\n",
    "print(pd.Series(y_smote).value_counts())\n",
    "\n",
    "print(\"\\nClass Distribution after ADASYN:\")\n",
    "print(pd.Series(y_adasyn).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4656a0",
   "metadata": {},
   "source": [
    "#### Undersampling\n",
    "Undersampling reduces the number of instances in the majority class by randomly removing samples. It can be effective when the dataset is large, and the majority class has many redundant instances. Common undersampling methods include Random Undersampling, NearMiss, and Tomek Links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1740de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "0    898\n",
      "1    102\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Class Distribution after Random Undersampling:\n",
      "0    102\n",
      "1    102\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Class Distribution after NearMiss:\n",
      "0    102\n",
      "1    102\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Class Distribution after TomekLinks:\n",
      "0    886\n",
      "1    102\n",
      "Name: Target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "# Create a sample imbalanced dataset\n",
    "np.random.seed(0)\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=5,\n",
    "    n_informative=3,\n",
    "    n_redundant=2,\n",
    "    n_classes=2,\n",
    "    weights=[0.9, 0.1],  # Imbalanced class distribution\n",
    ")\n",
    "\n",
    "# Convert the dataset into a DataFrame\n",
    "data = pd.DataFrame(X, columns=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5'])\n",
    "data['Target'] = y\n",
    "\n",
    "# Check the class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(data['Target'].value_counts())\n",
    "\n",
    "# Random Undersampling\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_rus, y_rus = rus.fit_resample(data.drop('Target', axis=1), data['Target'])\n",
    "\n",
    "# NearMiss\n",
    "nm = NearMiss(version=1)\n",
    "X_nm, y_nm = nm.fit_resample(data.drop('Target', axis=1), data['Target'])\n",
    "\n",
    "# TomekLinks\n",
    "tl = TomekLinks()\n",
    "X_tl, y_tl = tl.fit_resample(data.drop('Target', axis=1), data['Target'])\n",
    "\n",
    "# Check the class distribution after undersampling\n",
    "print(\"\\nClass Distribution after Random Undersampling:\")\n",
    "print(pd.Series(y_rus).value_counts())\n",
    "\n",
    "print(\"\\nClass Distribution after NearMiss:\")\n",
    "print(pd.Series(y_nm).value_counts())\n",
    "\n",
    "print(\"\\nClass Distribution after TomekLinks:\")\n",
    "print(pd.Series(y_tl).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c585e170",
   "metadata": {},
   "source": [
    "#### Class Weighting\n",
    "Assigning class weights can be used to give more importance to the minority class during model training. This approach is applicable to algorithms that accept class weights as a parameter, such as decision trees or support vector machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e996808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "0    898\n",
      "1    102\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.73      0.81       173\n",
      "           1       0.22      0.48      0.30        27\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.56      0.60      0.55       200\n",
      "weighted avg       0.81      0.69      0.74       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a sample imbalanced dataset\n",
    "np.random.seed(0)\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=5,\n",
    "    n_informative=3,\n",
    "    n_redundant=2,\n",
    "    n_classes=2,\n",
    "    weights=[0.9, 0.1],  # Imbalanced class distribution\n",
    ")\n",
    "\n",
    "# Convert the dataset into a DataFrame\n",
    "data = pd.DataFrame(X, columns=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5'])\n",
    "data['Target'] = y\n",
    "\n",
    "# Check the class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(data['Target'].value_counts())\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('Target', axis=1), data['Target'], test_size=0.2, random_state=0)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = dict(1 / data['Target'].value_counts())\n",
    "\n",
    "# Create and train the model with class weighting\n",
    "model = LogisticRegression(class_weight=class_weights)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb94df6",
   "metadata": {},
   "source": [
    "#### Ensemble Techniques\n",
    "Ensemble methods combine multiple models to improve predictive performance. They can be effective for imbalanced data by giving more importance to the minority class. Examples include Balanced Random Forest and EasyEnsemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1a1df80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      "0    898\n",
      "1    102\n",
      "Name: Target, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RACHIT\\anaconda3\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:546: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\RACHIT\\anaconda3\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:558: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report - Balanced Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       173\n",
      "           1       0.62      0.78      0.69        27\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.79      0.85      0.82       200\n",
      "weighted avg       0.92      0.91      0.91       200\n",
      "\n",
      "\n",
      "Classification Report - Easy Ensemble Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.84      0.90       173\n",
      "           1       0.44      0.81      0.57        27\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.70      0.83      0.73       200\n",
      "weighted avg       0.90      0.83      0.85       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "\n",
    "# Create a sample imbalanced dataset\n",
    "np.random.seed(0)\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=5,\n",
    "    n_informative=3,\n",
    "    n_redundant=2,\n",
    "    n_classes=2,\n",
    "    weights=[0.9, 0.1],  # Imbalanced class distribution\n",
    ")\n",
    "\n",
    "# Convert the dataset into a DataFrame\n",
    "data = pd.DataFrame(X, columns=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5'])\n",
    "data['Target'] = y\n",
    "\n",
    "# Check the class distribution\n",
    "print(\"Class Distribution:\")\n",
    "print(data['Target'].value_counts())\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('Target', axis=1), data['Target'], test_size=0.2, random_state=0)\n",
    "\n",
    "# Balanced Random Forest Classifier\n",
    "brf = BalancedRandomForestClassifier(random_state=0)\n",
    "brf.fit(X_train, y_train)\n",
    "y_pred_brf = brf.predict(X_test)\n",
    "\n",
    "# Easy Ensemble Classifier\n",
    "eec = EasyEnsembleClassifier(random_state=0)\n",
    "eec.fit(X_train, y_train)\n",
    "y_pred_eec = eec.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "print(\"\\nClassification Report - Balanced Random Forest Classifier:\")\n",
    "print(classification_report(y_test, y_pred_brf))\n",
    "\n",
    "print(\"\\nClassification Report - Easy Ensemble Classifier:\")\n",
    "print(classification_report(y_test, y_pred_eec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645bd61",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics\n",
    "Instead of using standard accuracy, consider using evaluation metrics that are more appropriate for imbalanced data, such as precision, recall, F1-score, or area under the ROC curve (AUC-ROC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17d55873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "276038e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROC AUC Score: 0.6049025904517233\n",
      "\n",
      "ROC AUC Score: 0.9173624491543566\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities of class 1 (positive class)\n",
    "y_pred_proba = brf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the ROC AUC score with out predict_proba() method\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"\\nROC AUC Score:\", roc_auc)\n",
    "\n",
    "# Calculate the ROC AUC score with predict_proba() method\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"\\nROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1af60a",
   "metadata": {},
   "source": [
    "## Data Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81566b68",
   "metadata": {},
   "source": [
    "#### Concatenation\n",
    "Concatenation is the simplest technique that involves merging datasets vertically or horizontally based on a common key or index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "469d451b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated Data:\n",
      "   ID  Feature1 Feature2\n",
      "0   1       0.5        A\n",
      "1   2       0.8        B\n",
      "2   3       0.2        C\n",
      "3   4       0.4        D\n",
      "0   5       0.9        E\n",
      "1   6       0.7        F\n",
      "2   7       0.3        G\n",
      "3   8       0.6        H\n"
     ]
    }
   ],
   "source": [
    "# Create sample datasets\n",
    "dataset1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    'Feature1': [0.5, 0.8, 0.2, 0.4],\n",
    "    'Feature2': ['A', 'B', 'C', 'D']\n",
    "})\n",
    "\n",
    "dataset2 = pd.DataFrame({\n",
    "    'ID': [5, 6, 7, 8],\n",
    "    'Feature1': [0.9, 0.7, 0.3, 0.6],\n",
    "    'Feature2': ['E', 'F', 'G', 'H']\n",
    "})\n",
    "\n",
    "# Concatenate the datasets along rows\n",
    "concatenated_data = pd.concat([dataset1, dataset2], axis=0)\n",
    "\n",
    "# Print the concatenated dataset\n",
    "print(\"Concatenated Data:\")\n",
    "print(concatenated_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ba3c5b",
   "metadata": {},
   "source": [
    "#### Joins\n",
    "Joins are used to combine datasets based on common columns or keys. Common types of joins include inner join, left join, right join, and full outer join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b895a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner Join:\n",
      "   ID Feature1  Feature2 Feature3  Feature4\n",
      "0   3        C        30        X        50\n",
      "1   4        D        40        Y        60\n",
      "\n",
      "Left Join:\n",
      "   ID Feature1  Feature2 Feature3  Feature4\n",
      "0   1        A        10      NaN       NaN\n",
      "1   2        B        20      NaN       NaN\n",
      "2   3        C        30        X      50.0\n",
      "3   4        D        40        Y      60.0\n",
      "\n",
      "Right Join:\n",
      "   ID Feature1  Feature2 Feature3  Feature4\n",
      "0   3        C      30.0        X        50\n",
      "1   4        D      40.0        Y        60\n",
      "2   5      NaN       NaN        Z        70\n",
      "3   6      NaN       NaN        W        80\n",
      "\n",
      "Outer Join:\n",
      "   ID Feature1  Feature2 Feature3  Feature4\n",
      "0   1        A      10.0      NaN       NaN\n",
      "1   2        B      20.0      NaN       NaN\n",
      "2   3        C      30.0        X      50.0\n",
      "3   4        D      40.0        Y      60.0\n",
      "4   5      NaN       NaN        Z      70.0\n",
      "5   6      NaN       NaN        W      80.0\n"
     ]
    }
   ],
   "source": [
    "# Create sample datasets\n",
    "data1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    'Feature1': ['A', 'B', 'C', 'D'],\n",
    "    'Feature2': [10, 20, 30, 40]\n",
    "})\n",
    "\n",
    "data2 = pd.DataFrame({\n",
    "    'ID': [3, 4, 5, 6],\n",
    "    'Feature3': ['X', 'Y', 'Z', 'W'],\n",
    "    'Feature4': [50, 60, 70, 80]\n",
    "})\n",
    "\n",
    "# Perform inner join\n",
    "inner_join = pd.merge(data1, data2, on='ID', how='inner')\n",
    "print(\"Inner Join:\")\n",
    "print(inner_join)\n",
    "\n",
    "# Perform left join\n",
    "left_join = pd.merge(data1, data2, on='ID', how='left')\n",
    "print(\"\\nLeft Join:\")\n",
    "print(left_join)\n",
    "\n",
    "# Perform right join\n",
    "right_join = pd.merge(data1, data2, on='ID', how='right')\n",
    "print(\"\\nRight Join:\")\n",
    "print(right_join)\n",
    "\n",
    "# Perform outer join\n",
    "outer_join = pd.merge(data1, data2, on='ID', how='outer')\n",
    "print(\"\\nOuter Join:\")\n",
    "print(outer_join)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1311e1ef",
   "metadata": {},
   "source": [
    "#### Union\n",
    "Union combines rows from multiple datasets into a single dataset, and it is commonly used when datasets have the same structure and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a52fec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union Dataset:\n",
      "   A  B\n",
      "0  1  a\n",
      "1  2  b\n",
      "2  3  c\n",
      "3  4  d\n",
      "4  5  e\n",
      "5  6  f\n"
     ]
    }
   ],
   "source": [
    "# Create sample datasets\n",
    "data1 = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})\n",
    "data2 = pd.DataFrame({'A': [4, 5, 6], 'B': ['d', 'e', 'f']})\n",
    "\n",
    "# Perform union operation\n",
    "union_data = pd.concat([data1, data2], ignore_index=True)\n",
    "\n",
    "# Print the union dataset\n",
    "print(\"Union Dataset:\")\n",
    "print(union_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5586c",
   "metadata": {},
   "source": [
    "#### Data Matching\n",
    "Data matching involves identifying and linking similar or matching records across datasets based on common attributes. Techniques like fuzzy matching or record linkage can be used for data matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "326fa400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Matching Record:\n",
      "Name       John Smith\n",
      "Phone    123-456-7890\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RACHIT\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Create sample dataset\n",
    "data = pd.DataFrame({'Name': ['John Smith', 'Jane Doe', 'Mark Johnson', 'David Williams'],\n",
    "                     'Phone': ['123-456-7890', '555-123-4567', '987-654-3210', '123-123-4567']})\n",
    "\n",
    "# Target string for fuzzy matching\n",
    "target_string = 'John Smtih'\n",
    "\n",
    "# Perform fuzzy matching using process.extractOne()\n",
    "best_match = process.extractOne(target_string, data['Name'])\n",
    "best_match_index = best_match[2]\n",
    "\n",
    "# Get the best matching record\n",
    "matched_record = data.loc[best_match_index]\n",
    "\n",
    "# Print the best matching record\n",
    "print(\"Best Matching Record:\")\n",
    "print(matched_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00e907f",
   "metadata": {},
   "source": [
    "#### Entity Resolution\n",
    "Entity Resolution, also known as Record Linkage or Deduplication, is the process of identifying and merging records from different datasets that refer to the same real-world entity. This technique is particularly useful when dealing with data from multiple sources that contain duplicate or overlapping information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "229af3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n",
      "Matches:\n",
      "       0    1\n",
      "0 0  1.0  1.0\n",
      "  2  0.0  1.0\n",
      "1 1  1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "import recordlinkage\n",
    "\n",
    "# Create sample datasets\n",
    "data1 = pd.DataFrame({'ID': [1, 2, 3],\n",
    "                      'Name': ['John Smith', 'Jane Doe', 'Mark Johnson'],\n",
    "                      'Phone': ['123-456-7890', '555-123-4567', '987-654-3210']})\n",
    "\n",
    "data2 = pd.DataFrame({'ID': [4, 5, 6],\n",
    "                      'Name': ['John Smith', 'Jane Doe', 'David Williams'],\n",
    "                      'Phone': ['123-456-7890', '555-123-4567', '123-123-4567']})\n",
    "\n",
    "# Create indexer\n",
    "indexer = recordlinkage.Index()\n",
    "indexer.full()\n",
    "\n",
    "# Generate pairs\n",
    "pairs = indexer.index(data1, data2)\n",
    "\n",
    "# Create comparison algorithm\n",
    "compare = recordlinkage.Compare()\n",
    "\n",
    "# Compare fields for similarity\n",
    "compare.string('Name', 'Name', method='jarowinkler', threshold=0.85)\n",
    "compare.string('Phone', 'Phone', method='jarowinkler', threshold=0.85)\n",
    "\n",
    "# Compute similarity scores\n",
    "scores = compare.compute(pairs, data1, data2)\n",
    "\n",
    "# Select matches above threshold\n",
    "matches = scores[scores.sum(axis=1) >= 1]\n",
    "\n",
    "# Print matches\n",
    "print(\"Matches:\")\n",
    "print(matches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a8e76d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
